{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification:\n",
    "X => n_samples x n_features array  \n",
    "Y => n_samples array (discrete labels)  \n",
    "SVM: X => Y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 300\n",
    "X, Y = datasets.make_blobs(n_features=2, centers=3, n_samples=N)\n",
    "split = int(N/2)\n",
    "train_X = X[:split, :]\n",
    "test_X = X[split:, :]\n",
    "train_Y = Y[:split]\n",
    "test_Y = Y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Three blobs\")\n",
    "plt.scatter(X[:, 0], X[:, 1], marker='o', c=Y, s=25, edgecolor='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel='rbf', gamma=0.7)\n",
    "model.fit(train_X,train_Y)\n",
    "predicted_Y = model.predict(test_X)\n",
    "mismatches = np.array([instance for index, instance in enumerate(test_X)\n",
    "                       if predicted_Y[index] != test_Y[index]])\n",
    "\n",
    "plt.title(\"Predicted\")\n",
    "plt.scatter(test_X[:, 0], test_X[:, 1], marker='o', c=predicted_Y, s=25, edgecolor='k')\n",
    "if len(mismatches)>0:\n",
    "    plt.scatter(mismatches[:,0], mismatches[:,1], marker='x', c='red')\n",
    "else:\n",
    "    print('Perfect Test Performance!')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A note about kernels\n",
    "SVM \"kernels\" are really just so-called \"kernel function\" functions that compute an inner product (think dot product). They provide a similarity measure in a corresponding coordinate space. These kernel functions can be used to simulate projecting the data to higher dimensions (think about reshaping a plane as a 2-d parabola embedded in 3 dimensions). The SVM is still using linear separators (hyperplanes) in the higher dimension, but these separators can induce non-linear \"decision boundaries\" in the lower dimensional space.\n",
    "If that all sounds confusing, don't worry about it. The important takeaway is that SVM's can represent very complicated classification functions. In practice, nearly everyone uses the radial basis function (RBF) kernel. The RBF kernel has a single parameter (usually called gamma) that you can adjust to possibly improve your accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./book_sales_data.json\", \"r\") as infile:\n",
    "    book_sales_data = json.load(infile)\n",
    "print(len(book_sales_data))\n",
    "print(book_sales_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Only run this once, ever. The validation data should never be changed.\n",
    "\n",
    "from sklearn import model_selection\n",
    "work_data, validation_data = model_selection.train_test_split(book_sales_data, test_size = .10)\n",
    "\n",
    "with open(\"./book_sales_work_data.json\", \"w\") as outfile:\n",
    "    json.dump(work_data, outfile)\n",
    "\n",
    "with open(\"./book_sales_validation_data.json\", \"w\") as outfile:\n",
    "    json.dump(validation_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "\n",
    "# Use increasing amounds of training data and measure performance on the same test set.\n",
    "with open(\"./book_sales_work_data.json\", \"r\") as infile:\n",
    "    book_sales_work_data = json.load(infile)\n",
    "\n",
    "train_data, test_data = model_selection.train_test_split(book_sales_work_data, test_size = .20)\n",
    "print(\"Training Length: \", len(train_data), \" Testing Length: \", len(test_data))\n",
    "\n",
    "def convert_book_data_to_arrays(data_to_convert, regress=False):\n",
    "    dtc = data_to_convert\n",
    "    inputs = [[dtc[i][\"book_details_time\"], dtc[i][\"homepage_time\"],\n",
    "               dtc[i][\"total_web_time_minutes\"]]\n",
    "              for i in range(len(dtc))]\n",
    "    if not regress:  # If for classification\n",
    "        outputs = [dtc[i][\"paying_customer\"]\n",
    "                  for i in range(len(dtc))]\n",
    "    else:\n",
    "        outputs = [dtc[i][\"books_sold\"]\n",
    "          for i in range(len(dtc))]\n",
    "    return inputs, outputs\n",
    "\n",
    "# Split the test set into inputs and expected outputs\n",
    "test_X, test_Y = convert_book_data_to_arrays(test_data)\n",
    "\n",
    "num_parts = 100\n",
    "data_sizes = [math.floor(1/num_parts * (i+1) * len(train_data)) for i in range(num_parts)] # measure by 10ths.\n",
    "accuracies = []\n",
    "for data_size in data_sizes:\n",
    "    train_subset = train_data[:data_size]\n",
    "    train_X, train_Y = convert_book_data_to_arrays(train_subset)\n",
    "    \n",
    "    # train model\n",
    "    model = svm.SVC(kernel='rbf', gamma=0.7)\n",
    "    model.fit(train_X,train_Y)\n",
    "    \n",
    "    # measure accuracy on the test data\n",
    "    predicted_Y = model.predict(test_X)\n",
    "    accuracy = np.mean([predicted_Y[i] == test_Y[i] for i in range(len(predicted_Y))])\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "# plot accuracy vs. number of training points.\n",
    "plt.plot(data_sizes, accuracies)\n",
    "plt.xlabel('Number of Training Points')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting and Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# The AdaBoostClassifier uses shallow decision trees by default.\n",
    "\n",
    "#Plot test accuracy vs. number of classifiers in the ensemble\n",
    "num_classifiers = list(range(1, 200+1))\n",
    "train_accuracies = []\n",
    "accuracies = []\n",
    "for n in num_classifiers:\n",
    "    model = AdaBoostClassifier(n_estimators=n)\n",
    "    model.fit(train_X, train_Y)\n",
    "    \n",
    "    # measure training accuracy on the test data\n",
    "    predicted_Y = model.predict(train_X)\n",
    "    accuracy = np.mean([predicted_Y[i] == train_Y[i] for i in range(len(predicted_Y))])\n",
    "    train_accuracies.append(accuracy)\n",
    "    \n",
    "    # measure accuracy on the test data\n",
    "    predicted_Y = model.predict(test_X)\n",
    "    accuracy = np.mean([predicted_Y[i] == test_Y[i] for i in range(len(predicted_Y))])\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "plt.plot(num_classifiers, accuracies, label=\"test accuracy\")\n",
    "plt.plot(num_classifiers, train_accuracies, label=\"train accuracy\")\n",
    "plt.xlabel('Number of Classifiers in the Ensemble')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_toy_data = 200\n",
    "toy_split = total_toy_data//2\n",
    "all_data = [[np.random.random(), np.random.random()] for i in range(total_toy_data)]\n",
    "# below is just a made-up classification for the purpose of creating a harder but deterministic problem.\n",
    "ys = [(datum[0]-.5)**3 - (datum[0]-.5)**2 + math.sin(datum[0]*20) < datum[1] for datum in all_data]\n",
    "toy_train_X, toy_train_Y = all_data[:toy_split], ys[:toy_split]\n",
    "toy_test_X, toy_test_Y = all_data[toy_split:], ys[toy_split:]\n",
    "\n",
    "#Plot test accuracy vs. number of classifiers in the ensemble\n",
    "num_classifiers = list(range(1, 200+1))\n",
    "train_accuracies = []\n",
    "accuracies = []\n",
    "for n in num_classifiers:\n",
    "    model = AdaBoostClassifier(n_estimators=n)\n",
    "    model.fit(toy_train_X, toy_train_Y)\n",
    "    \n",
    "    # measure training accuracy on the test data\n",
    "    predicted_Y = model.predict(toy_train_X)\n",
    "    accuracy = np.mean([predicted_Y[i] == toy_train_Y[i] for i in range(len(predicted_Y))])\n",
    "    train_accuracies.append(accuracy)\n",
    "    \n",
    "    # measure accuracy on the test data\n",
    "    predicted_Y = model.predict(toy_test_X)\n",
    "    accuracy = np.mean([predicted_Y[i] == toy_test_Y[i] for i in range(len(predicted_Y))])\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "plt.plot(num_classifiers, accuracies, label=\"test accuracy\")\n",
    "plt.plot(num_classifiers, train_accuracies, label=\"train accuracy\")\n",
    "plt.xlabel('Number of Classifiers in the Ensemble')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "with open(\"./book_sales_work_data.json\", \"r\") as infile:\n",
    "    all_work_data_X, all_work_data_Y = convert_book_data_to_arrays(json.load(infile))\n",
    "\n",
    "model = svm.SVC(kernel='rbf', gamma=0.7)\n",
    "scores = cross_val_score(model, all_work_data_X, all_work_data_Y, cv=10)\n",
    "print(scores)\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data for regression task and classification task.\n",
    "with open(\"./book_sales_work_data.json\", \"r\") as infile:\n",
    "    train_data, test_data = model_selection.train_test_split(json.load(infile), test_size = .20)\n",
    "\n",
    "class_train_X, class_train_Y = convert_book_data_to_arrays(train_data)\n",
    "class_test_X, class_test_Y = convert_book_data_to_arrays(test_data)\n",
    "\n",
    "regress_train_X, regress_train_Y = convert_book_data_to_arrays(train_data, regress=True)\n",
    "regress_test_X, regress_test_Y = convert_book_data_to_arrays(test_data, regress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define our neural network\n",
    "class RegressionNet(nn.Module):\n",
    "    def __init__(self, width):\n",
    "        \"\"\"width should be a natural number\"\"\"\n",
    "        width = max(width, 1)\n",
    "        \n",
    "        super(self.__class__, self).__init__()\n",
    "        \n",
    "        #Define the pass-forward weights\n",
    "        #Goes from 1 to width back to 1, with a nonlinear function in between.\n",
    "        self.forward_1 = nn.Linear(3,width)\n",
    "        self.forward_2 = nn.Linear(width,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.forward_2(F.relu(self.forward_1(x)))\n",
    "        return x\n",
    "    \n",
    "    def infer_class(self, x):\n",
    "        # Purely for convenience\n",
    "        \"\"\"Run the input forward, but then round to the nearest integer.\"\"\"\n",
    "        return int(math.floor(self.forward(x) + .5))\n",
    "\n",
    "# Sometimes called the \"criterion\"\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_wrap(some_data, convert_type=np.float):\n",
    "    return Variable(torch.from_numpy(np.array(some_data).astype(convert_type)).float())\n",
    "\n",
    "def list_map(*args, **kwargs):\n",
    "    # A helper function to unroll a list generated by mapping a function\n",
    "    #     onto elements of another list.\n",
    "    # args stores unnamed arguments, and kwargs stores named arguments\n",
    "    return list(map(*args,**kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "def learn_on_data(train_X, train_Y, test_X, test_Y, regress=False, model_width=10, file_base=\"./\"):\n",
    "    model = RegressionNet(model_width)\n",
    "    optimizer = Adam(model.parameters())\n",
    "\n",
    "    # Format the input to be read by the network.\n",
    "    var_train_X, var_train_Y = list_map(variable_wrap, train_X), list_map(variable_wrap, train_Y)\n",
    "    var_test_X, var_test_Y = list_map(variable_wrap, test_X), list_map(variable_wrap, test_Y)\n",
    "    \n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    for data_loop in range(300):\n",
    "        model.train() # Set the network to training mode. Affects some layers sometimes.\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        # Loop through the data and use the gradient to optimize the model parameters.\n",
    "        for train_index in range(len(train_X)):\n",
    "            X, Y = var_train_X[train_index], var_train_Y[train_index]\n",
    "\n",
    "            #print(Y)\n",
    "            predicted_Y = model.forward(X)\n",
    "            #print(predicted_Y.item())\n",
    "            loss = loss_function(predicted_Y, Y)\n",
    "            #print(loss.item())\n",
    "            loss.backward() # Stores the gradient for all parameters.\n",
    "        optimizer.step() # Doing this outside the loop accumulates gradients across all data points.\n",
    "\n",
    "        # Measure train and test accuracy\n",
    "        model.eval() # Set model to evaluation (testing) mode. Affects some models some time.\n",
    "        if not regress:\n",
    "            train_predicted = list_map(model.infer_class, var_train_X)\n",
    "        else:\n",
    "            train_predicted = list_map(model.forward, var_train_X)\n",
    "        \n",
    "        if not regress:\n",
    "            matches = [train_predicted[i]==var_train_Y[i] for i in range(len(var_train_X))]\n",
    "            matches = list_map(int, matches) # Convert to Boolean to higher-represention-size int\n",
    "            train_accuracy = sum(matches)/len(var_train_X)\n",
    "        else:\n",
    "            # In this setting measure error as absolute value of the difference\n",
    "            error = [abs(train_predicted[i]-var_train_Y[i]) for i in range(len(var_train_X))]\n",
    "            #error = [(train_predicted[i]-var_train_Y[i])**2 for i in range(len(var_train_X))]\n",
    "            average_error = sum(error)/len(var_train_X)\n",
    "            train_accuracy = average_error\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        if not regress:\n",
    "            test_predicted = list_map(model.infer_class, var_test_X)\n",
    "        else:\n",
    "            test_predicted = list_map(model.forward, var_test_X)\n",
    "        \n",
    "        if not regress:\n",
    "            matches = [test_predicted[i]==var_test_Y[i] for i in range(len(var_test_X))]\n",
    "            matches = list_map(int, matches)\n",
    "            test_accuracy = sum(matches)/len(var_test_X)\n",
    "        else:\n",
    "            error = [abs(test_predicted[i]-var_test_Y[i]) for i in range(len(var_test_X))]\n",
    "            #error = [(test_predicted[i]-var_test_Y[i])**2 for i in range(len(var_test_X))]\n",
    "            average_error = sum(error)/len(var_test_X)\n",
    "            test_accuracy = average_error\n",
    "        test_accuracies.append(test_accuracy)\n",
    "    \n",
    "    if not regress:\n",
    "        plt.plot(range(len(train_accuracies)), train_accuracies, label=\"training_accuracy\")\n",
    "        plt.plot(range(len(test_accuracies)), test_accuracies, label=\"testing_accuracy\")\n",
    "        plt.xlabel('Passes through data')\n",
    "        plt.ylabel('Accuracy (higher is better)')\n",
    "        plt.title('Classification with a Neural Network')\n",
    "    else:\n",
    "        plt.plot(range(len(train_accuracies)), train_accuracies, label=\"training_accuracy\")\n",
    "        plt.plot(range(len(test_accuracies)), test_accuracies, label=\"testing_accuracy\")\n",
    "        plt.xlabel('Passes through data')\n",
    "        plt.ylabel('Average Error (lower is better)')\n",
    "        plt.title('Regression with a Neural Network')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "learn_on_data(class_train_X, class_train_Y, class_test_X, class_test_Y, regress=False)\n",
    "learn_on_data(regress_train_X, regress_train_Y, regress_test_X, regress_test_Y, regress=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A note about saving:\n",
    "For production, you'll generally want to save your most accurate model. Although that isn't demonstrated above, the commands are really simple:\n",
    "`torch.save(model, file_handle)`\n",
    "and\n",
    "`model = torch.load(file_handle)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
