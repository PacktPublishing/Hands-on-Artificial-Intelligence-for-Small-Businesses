{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Page Layouts and Advertisements  \n",
    "# using Reinforcement Learning  \n",
    "It's pretty hard to test reinforcement learning algorithms without some interaction with the environment, but it's also hard to give all the users of this course access to a live system to collect data on real customers, so the experiments will all be based on simulations. All of the code should work on live systems, however."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thompson Sampling\n",
    "Note that Thompson Sampling can change based on the distribution of rewards. Since a lot of business cases involve users either taking an action or not taking an action (replying to email, subscribing, clicking on ad, buying product, viewing page, etc.), we use a Bernoulli distribution (weighted coin flip) to represent the distribution over outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def mean_std(list_of_numbers):\n",
    "    return np.mean(list_of_numbers), np.std(list_of_numbers)\n",
    "\n",
    "def mean_ste(list_of_numbers):\n",
    "    mean, std = mean_std(list_of_numbers)\n",
    "    return mean, std/math.sqrt(len(list_of_numbers))\n",
    "\n",
    "def biased(list_of_numbers):\n",
    "    #Prevent std from being zero by adding phantom observations.\n",
    "    new_list = list_of_numbers.copy()\n",
    "    new_list.extend([1, 0])\n",
    "    return new_list\n",
    "\n",
    "class GaussianThompsonSampler:\n",
    "    \"\"\"Gaussians describe the statistics around means very well.\n",
    "        This class implements Thompson Sampling based on this.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def sample_arms(means, std_errs):\n",
    "        \"\"\"Takes arm statistics and returns a sampled index.\n",
    "            std_err is deviation in the mean, called the standard error.\"\"\"\n",
    "        # means and std_devs are assumed to correspond element for element.\n",
    "        samples = means.copy()\n",
    "        for index in range(len(means)):\n",
    "            if std_errs[index] > 0:\n",
    "                samples[index] = np.random.normal(means[index], std_errs[index])\n",
    "        max_ind = max(range(len(means)), key=lambda index: samples[index])\n",
    "        return max_ind\n",
    "    \n",
    "    @staticmethod\n",
    "    def sample_from_scores(scores_matrix):\n",
    "        \"\"\"scores_matrix is a list of lists of scores.\"\"\"\n",
    "        means = []\n",
    "        std_errs = []\n",
    "        for scores_list in scores_matrix:\n",
    "            mean, ste = mean_ste(biased(scores_list))\n",
    "            means.append(mean)\n",
    "            std_errs.append(ste)\n",
    "        return GaussianThompsonSampler.sample_arms(means, std_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arms = (\"a\", \"b\")\n",
    "scores_a = []\n",
    "scores_b = []\n",
    "for i in range(20):\n",
    "    #print(test_bts.max_sample(arms))\n",
    "    sampled_arm = arms[GaussianThompsonSampler.sample_from_scores([scores_a, scores_b])]\n",
    "    print(sampled_arm)\n",
    "    if sampled_arm == \"a\":\n",
    "        scores_a.append(0)\n",
    "    else:\n",
    "        scores_b.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infinite-Arm Thompson Sampling\n",
    "We add in a special arm/action representing drawing a new action from the pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InfiniteThompsonSampler:\n",
    "    @staticmethod\n",
    "    def sample_arms(means, std_errs):\n",
    "        \"\"\"Takes arm statistics and returns a sampled index.\n",
    "            std_err is deviation in the mean, called the standard error.\"\"\"\n",
    "        # means and std_devs are assumed to correspond element for element.\n",
    "        samples = means.copy()\n",
    "        for index in range(len(means)):\n",
    "            if std_errs[index] > 0:\n",
    "                samples[index] = np.random.normal(means[index], std_errs[index])\n",
    "        # Define the mean and std_dev of value for a new arm\n",
    "        new_mean, new_std = mean_std(biased(means)) # Prevent deterministic non-sampling\n",
    "        samples.append(np.random.normal(new_mean, new_std))\n",
    "        max_ind = max(range(len(samples)), key=lambda index: samples[index])\n",
    "        return max_ind\n",
    "    \n",
    "    @staticmethod\n",
    "    def sample_from_scores(scores_matrix):\n",
    "        \"\"\"scores_matrix is a list of lists of scores.\"\"\"\n",
    "        means = []\n",
    "        std_errs = []\n",
    "        for scores_list in scores_matrix:\n",
    "            mean, ste = mean_ste(biased(scores_list))\n",
    "            means.append(mean)\n",
    "            std_errs.append(ste)\n",
    "        return InfiniteThompsonSampler.sample_arms(means, std_errs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Test infinite arm-sampling.\n",
    "max_trials = 1000\n",
    "means=[np.random.uniform() for arm in range(max_trials)]\n",
    "print(\"sample means: \", means[:10])\n",
    "plt.plot(means, [1 for i in range(max_trials)], \".\")\n",
    "plt.show()\n",
    "\n",
    "all_cumulative_rewards = []\n",
    "sampler = InfiniteThompsonSampler\n",
    "print(sampler)\n",
    "cumulative_rewards = []\n",
    "cumulative_reward = 0.0\n",
    "scores = []\n",
    "for trial in range(max_trials):\n",
    "    index = sampler.sample_from_scores(scores)\n",
    "    if index >= len(scores): # If new arm\n",
    "        scores.append([])\n",
    "    reward = np.random.binomial(1, means[index])\n",
    "    cumulative_reward += reward\n",
    "    cumulative_rewards.append(cumulative_reward)\n",
    "    scores[index].append(reward) # That is, add 1 if it was a success, 0 if failure.\n",
    "all_cumulative_rewards.append(cumulative_rewards)\n",
    "print(\"Sampled from: \", len(totals))\n",
    "plt.plot(range(max_trials), range(max_trials), label=\"Benefit of Hindsight\")\n",
    "plt.plot(range(max_trials), all_cumulative_rewards[0], label=\"Thompson\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual Bandit Process\n",
    "\n",
    "We're going to make use of a free package called `GPy`. You can install it with the commands below, or find it on GitHub at https://github.com/SheffieldML/GPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These commands will install gpy on the system. It may take a while.\n",
    "#!conda update scipy\n",
    "!pip install gpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "# Define a simple test - context is randomly chosen between 0 and 1 uniformly.\n",
    "# Actions are either .1, .2, .3, .4, .5 ... 1.0\n",
    "actions = [.1 * i for i in range(1,10 + 1)]\n",
    "def true_reward(context, action):\n",
    "    return (math.sin(context * 3 + action) + 1)/2\n",
    "\n",
    "def noisy_reward(context, action):\n",
    "    return np.random.binomial(1, true_reward(context, action) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "import numpy as np\n",
    "\n",
    "num_steps = 100\n",
    "total_rewards = []\n",
    "total_r = 0\n",
    "true_rewards = []\n",
    "total_true_r = 0\n",
    "\n",
    "sampled_X = []\n",
    "sampled_Y = []\n",
    "\n",
    "for step in range(num_steps):\n",
    "    context = np.random.random() # Random value between 0 and 1\n",
    "    \n",
    "    context_actions = np.array([[context] + [action] for action in actions])\n",
    "    \n",
    "    # If there are no points, just choose a random action:\n",
    "    if len(sampled_X) == 0:\n",
    "        action_index = np.random.choice(range(len(actions)))\n",
    "    else:\n",
    "        # Fit a Gaussian process to the points so far and predict rewards for each action.\n",
    "        kernel = GPy.kern.RBF(input_dim=len(sampled_X[0]))\n",
    "        model = GPy.models.GPRegression(np.array(sampled_X), np.array(sampled_Y), kernel)\n",
    "        for i in range(5):\n",
    "            model.optimize('bfgs', max_iters=100) #Finds good Gaussian Process model parameters\n",
    "        # Then use a Thompson Sampler\n",
    "        predicted_means, predicted_stds = model.predict_noiseless(context_actions)\n",
    "        action_index = GaussianThompsonSampler.sample_arms(predicted_means, predicted_stds)\n",
    "    \n",
    "    action = actions[action_index]\n",
    "    reward = noisy_reward(context, action)\n",
    "    total_r += reward\n",
    "    total_rewards.append(total_r)\n",
    "    \n",
    "    sampled_X.append(context_actions[action_index])\n",
    "    sampled_Y.append([reward])\n",
    "    \n",
    "    # Compute True Reward for Comparison:\n",
    "    # This is the value if the reward function were perfectly well known.\n",
    "    total_true_r += max([true_reward(context, action) for action in actions])\n",
    "    true_rewards.append(total_true_r)\n",
    "\n",
    "plt.title(\"Contextual Bandit vs. Hindsight\")\n",
    "plt.plot(range(num_steps), true_rewards, label=\"Hindsight\")\n",
    "plt.plot(range(num_steps), total_rewards, label=\"Contextual Bandit\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
